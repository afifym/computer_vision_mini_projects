{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "• \n",
    "• \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import imutils\n",
    "\n",
    "def show_image(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        cv2.imshow(k, v)\n",
    "    while True:\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "def show_stacked(*args):\n",
    "    cv2.imshow(\"images\", np.hstack([*args]))\n",
    "    while True:\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('pill_01.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "h, w, d = image.shape\n",
    "show_image(image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Resizing\"\"\"\n",
    "\n",
    "resized = cv2.resize(image, (200, 200))\n",
    "# resized = imutils.resize(image, width=2000)\n",
    "\n",
    "show_image(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Rotation\"\"\"\n",
    "\n",
    "center = (w//2, h//2)\n",
    "M = cv2.getRotationMatrix2D(center, -45, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "# rotated = imutils.rotate(image, -45)\n",
    "# rotated = imutils.rotate_bound(image, 45)\n",
    "\n",
    "show_image(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Blurring / Smoothening\"\"\"\n",
    "blurred = cv2.GaussianBlur(image, (11,11), 0)\n",
    "    \n",
    "\"\"\"Sharpenning\"\"\"\n",
    "kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "sharpened = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "\"\"\"Brightness\"\"\"\n",
    "intensity_thresh=200\n",
    "_, image = cv2.threshold(image, intensity_thresh, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "\"\"\"Contrast\"\"\"\n",
    "contrast_factor=0.85\n",
    "if image.std() > 45.0:\n",
    "    image = np.array(image * contrast_factor, dtype=np.uint8)\n",
    "\n",
    "show_image(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Drawing\"\"\"\n",
    "\n",
    "output = image.copy()\n",
    "\n",
    "cv2.rectangle(output, (320, 60), (420, 160), (0,0,255), 10)\n",
    "cv2.circle(output, (300, 150), 20, (255, 0, 0), -1)\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.putText(output, \"Hello!!!\", (10, 25), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "show_image(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Canny Edges\"\"\"\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(image, (11,11), 0)\n",
    "edged = cv2.Canny(blurred, 20, 100)  # (image, min.Threshold, max.Threshold)\n",
    "\n",
    "show_image(edged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thresholding\"\"\"\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(image, (11,11), 0)\n",
    "thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "show_image(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contours\"\"\"\n",
    "\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "# output = image.copy()\n",
    "\n",
    "if len(cnts) > 0:\n",
    "    # grab the largest contour, then draw a mask for the pill\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    M = cv2.moments(c)\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "    cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "    # compute its bounding box of pill, then extract the ROI,\n",
    "    # and apply the mask\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    imageROI = image[y:y + h, x:x + w]\n",
    "    maskROI = mask[y:y + h, x:x + w]\n",
    "    imageROI = cv2.bitwise_and(imageROI, imageROI,\n",
    "        mask=maskROI)\n",
    "\n",
    "show_image(imageROI=imageROI,\n",
    "           mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Erosions and dilations\"\"\"\n",
    "\n",
    "mask = thresh.copy()\n",
    "mask = cv2.erode(mask, None, iterations=5)\n",
    "\n",
    "# mask = thresh.copy()\n",
    "# mask = cv2.dilate(mask, None, iterations=5)\n",
    "\n",
    "show_image(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Masking and bitwise operations\"\"\"\n",
    "\n",
    "mask = thresh.copy()\n",
    "output = cv2.bitwise_and(image, image, mask=mask)\n",
    "show_image(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Smoothening Filter\"\"\"\n",
    "image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "\"\"\"Sharpenning Image\"\"\"\n",
    "image = cv2.filter2D(image, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Color Detection\"\"\"\n",
    "\n",
    "boundaries = [\n",
    "([17, 15, 100], [50, 56, 200]),\n",
    "([86, 31, 4], [220, 88, 50]),\n",
    "([25, 146, 190], [62, 174, 250]),\n",
    "([103, 86, 65], [145, 133, 128])\n",
    "]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    for (lower, upper) in boundaries:\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\")\n",
    "        upper = np.array(upper, dtype = \"uint8\")\n",
    "        # find the colors within the specified boundaries and apply\n",
    "        # the mask\n",
    "        mask = cv2.inRange(image, lower, upper)\n",
    "        output = cv2.bitwise_and(image, image, mask = mask)\n",
    "        # show the images\n",
    "\n",
    "    cv2.imshow('images', np.hstack([image, output]))\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Color Transfer\"\"\"\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "source = cv2.imread('forest_dark.jpg')\n",
    "target = cv2.imread('tree_sunny.png')\n",
    "\n",
    "def image_stats(image):\n",
    "    # compute the mean and standard deviation of each channel\n",
    "    (l, a, b) = cv2.split(image)\n",
    "    (lMean, lStd) = (l.mean(), l.std())\n",
    "    (aMean, aStd) = (a.mean(), a.std())\n",
    "    (bMean, bStd) = (b.mean(), b.std())\n",
    "    # return the color statistics\n",
    "    return (lMean, lStd, aMean, aStd, bMean, bStd)\n",
    "\n",
    "\n",
    "def color_transfer(source, target):\n",
    "    # convert the images from the RGB to L*ab* color space, being\n",
    "    # sure to utilizing the floating point data type (note: OpenCV\n",
    "    # expects floats to be 32-bit, so use that instead of 64-bit)\n",
    "    source = cv2.cvtColor(source, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(\"float32\")\n",
    "\n",
    "    # compute color statistics for the source and target images\n",
    "\n",
    "    (lMeanSrc, lStdSrc, aMeanSrc, aStdSrc, bMeanSrc, bStdSrc) = image_stats(source)\n",
    "    (lMeanTar, lStdTar, aMeanTar, aStdTar, bMeanTar, bStdTar) = image_stats(target)\n",
    "    # subtract the means from the target image\n",
    "    (l, a, b) = cv2.split(target)\n",
    "    l -= lMeanTar\n",
    "    a -= aMeanTar\n",
    "    b -= bMeanTar\n",
    "    # scale by the standard deviations\n",
    "    l = (lStdTar / lStdSrc) * l\n",
    "    a = (aStdTar / aStdSrc) * a\n",
    "    b = (bStdTar / bStdSrc) * b\n",
    "    # add in the source mean\n",
    "    l += lMeanSrc\n",
    "    a += aMeanSrc\n",
    "    b += bMeanSrc\n",
    "    # clip the pixel intensities to [0, 255] if they fall outside\n",
    "    # this range\n",
    "    l = np.clip(l, 0, 255)\n",
    "    a = np.clip(a, 0, 255)\n",
    "    b = np.clip(b, 0, 255)\n",
    "    # merge the channels together and convert back to the RGB color\n",
    "    # space, being sure to utilize the 8-bit unsigned integer data\n",
    "    # type\n",
    "    transfer = cv2.merge([l, a, b])\n",
    "    transfer = cv2.cvtColor(transfer.astype(\"uint8\"), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # return the color transferred image\n",
    "    return transfer\n",
    "\n",
    "show_image(transfer=color_transfer(source, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'four_point_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-817017ca014e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# apply the four point transform to obtain a top-down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# view of the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfour_point_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreenCnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m# convert the warped image to grayscale, then threshold it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# to give it that 'black and white' paper effect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'four_point_transform' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "params = {'New Height': 500}\n",
    "while True:\n",
    "    ret, image = cap.read()\n",
    "    resized = imutils.resize(image, height=params['New Height'])\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    ratio = gray.shape[0]/params['New Height']\n",
    "    \n",
    "    blur = cv2.GaussianBlur(resized, (5,5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    "    \n",
    "    cnts = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "    \n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02*peri, True)\n",
    "        \n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            break\n",
    "            \n",
    "    cv2.drawContours(gray, [screenCnt], -1, (0,255,0), 2)\n",
    "    \n",
    "    # apply the four point transform to obtain a top-down\n",
    "    # view of the original image\n",
    "    warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "    # convert the warped image to grayscale, then threshold it\n",
    "    # to give it that 'black and white' paper effect\n",
    "    warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    T = threshold_local(warped, 11, offset = 10, method = \"gaussian\")\n",
    "    warped = (warped > T).astype(\"uint8\") * 255\n",
    "    \n",
    "    cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "    cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sampling THREADED frames from webcam...\n",
      "[INFO] elasped time: 0.01\n",
      "[INFO] approx. FPS: 76893.50\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from imutils.video import WebcamVideoStream\n",
    "from imutils.video import FPS\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(\"[INFO] sampling THREADED frames from webcam...\")\n",
    "vs = WebcamVideoStream(src=0).start()\n",
    "fps = FPS().start()\n",
    "k=0\n",
    "while k<1000:\n",
    "    k+=1\n",
    "    frame = vs.read()\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    fps.update()\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): break\n",
    "cv2.destroyAllWindows()\n",
    "    # stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sampling THREADED frames from webcam...\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from imutils.video import WebcamVideoStream\n",
    "from imutils.video import FPS\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(\"[INFO] sampling THREADED frames from webcam...\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "fps = FPS().start()\n",
    "k=0\n",
    "while k<1000:\n",
    "    k+=1\n",
    "    frame = cap.read()\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    fps.update()\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): break\n",
    "cv2.destroyAllWindows()\n",
    "    # stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some Useful Funcitons\"\"\"\n",
    "\n",
    "# counting the number of non-zero pixels in an image\n",
    "total = cv2.countNonZero(image)\n",
    "\n",
    "# sorting found contours from top to bottom in a list\n",
    "t = contours.sort_contours(questionCnts, method=\"top-to-bottom\")[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
